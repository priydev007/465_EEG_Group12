{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Project Group 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Data and Performing Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here upto and including EEG Feature Extraction was taken from the sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priyd\\Downloads\\465_EEG_Group12\n",
      "                     TimeStamp  Delta_TP9  Delta_AF7  Delta_AF8  Delta_TP10  \\\n",
      "0      2024-11-21 14:04:16.799        NaN        NaN        NaN         NaN   \n",
      "1      2024-11-21 14:04:16.829   1.142701   0.842652   0.237114    1.623223   \n",
      "2      2024-11-21 14:04:16.829   1.142701   0.842652   0.237114    1.623223   \n",
      "3      2024-11-21 14:04:16.829   1.142701   0.842652   0.237114    1.623223   \n",
      "4      2024-11-21 14:04:16.830   1.142701   0.842652   0.237114    1.623223   \n",
      "...                        ...        ...        ...        ...         ...   \n",
      "17760  2024-11-21 14:05:25.887   0.743850   0.394492   1.152595    0.889482   \n",
      "17761  2024-11-21 14:05:25.887   0.743850   0.394492   1.152595    0.889482   \n",
      "17762  2024-11-21 14:05:25.887   0.743850   0.394492   1.152595    0.889482   \n",
      "17763  2024-11-21 14:05:25.887   0.743850   0.394492   1.152595    0.889482   \n",
      "17764  2024-11-21 14:05:25.887   0.743850   0.394492   1.152595    0.889482   \n",
      "\n",
      "       Theta_TP9  Theta_AF7  Theta_AF8  Theta_TP10  Alpha_TP9  ...   Gyro_X  \\\n",
      "0            NaN        NaN        NaN         NaN        NaN  ...      NaN   \n",
      "1       0.602743   0.191248   0.007583    1.703722   0.233287  ...  3.39447   \n",
      "2       0.602743   0.191248   0.007583    1.703722   0.233287  ...  3.39447   \n",
      "3       0.602743   0.191248   0.007583    1.703722   0.233287  ...  3.39447   \n",
      "4       0.602743   0.191248   0.007583    1.703722   0.233287  ...  3.39447   \n",
      "...          ...        ...        ...         ...        ...  ...      ...   \n",
      "17760   0.575718   0.232133   0.394247   -0.269688   0.402307  ... -4.63562   \n",
      "17761   0.575718   0.232133   0.394247   -0.269688   0.402307  ... -4.63562   \n",
      "17762   0.575718   0.232133   0.394247   -0.269688   0.402307  ... -4.63562   \n",
      "17763   0.575718   0.232133   0.394247   -0.269688   0.402307  ... -4.63562   \n",
      "17764   0.575718   0.232133   0.394247   -0.269688   0.402307  ... -4.63562   \n",
      "\n",
      "          Gyro_Y    Gyro_Z  HeadBandOn  HSI_TP9  HSI_AF7  HSI_AF8  HSI_TP10  \\\n",
      "0            NaN       NaN         NaN      NaN      NaN      NaN       NaN   \n",
      "1      -9.443207 -0.575714         1.0      2.0      1.0      1.0       2.0   \n",
      "2      -9.443207 -0.575714         1.0      2.0      1.0      1.0       2.0   \n",
      "3      -9.443207 -0.575714         1.0      2.0      1.0      1.0       2.0   \n",
      "4      -9.443207 -0.575714         1.0      2.0      1.0      1.0       2.0   \n",
      "...          ...       ...         ...      ...      ...      ...       ...   \n",
      "17760 -13.241425 -1.315918         1.0      2.0      1.0      1.0       2.0   \n",
      "17761 -13.241425 -1.315918         1.0      2.0      1.0      1.0       2.0   \n",
      "17762 -13.241425 -1.315918         1.0      2.0      1.0      1.0       2.0   \n",
      "17763 -13.241425 -1.315918         1.0      2.0      1.0      1.0       2.0   \n",
      "17764 -13.241425 -1.315918         1.0      2.0      1.0      1.0       2.0   \n",
      "\n",
      "       Battery                         Elements  \n",
      "0          NaN  /muse/event/connected Muse-9E89  \n",
      "1         90.0                              NaN  \n",
      "2         90.0                              NaN  \n",
      "3         90.0                              NaN  \n",
      "4         90.0                              NaN  \n",
      "...        ...                              ...  \n",
      "17760     90.0                              NaN  \n",
      "17761     90.0                              NaN  \n",
      "17762     90.0                              NaN  \n",
      "17763     90.0                              NaN  \n",
      "17764     90.0                              NaN  \n",
      "\n",
      "[17765 rows x 39 columns]\n",
      "                     TimeStamp  Delta_TP9  Delta_AF7  Delta_AF8  Delta_TP10  \\\n",
      "0      2024-11-21 13:55:13.012        NaN        NaN        NaN         NaN   \n",
      "1      2024-11-21 13:55:13.049    0.00000   1.017581   1.494045    0.000000   \n",
      "2      2024-11-21 13:55:13.050    0.00000   1.017581   1.494045    0.000000   \n",
      "3      2024-11-21 13:55:13.050    0.00000   1.017581   1.494045    0.000000   \n",
      "4      2024-11-21 13:55:13.050    0.00000   1.017581   1.494045    0.000000   \n",
      "...                        ...        ...        ...        ...         ...   \n",
      "20255  2024-11-21 13:56:31.763    1.07758   0.489131   1.025969    0.445634   \n",
      "20256  2024-11-21 13:56:31.763    1.07758   0.489131   1.025969    0.445634   \n",
      "20257  2024-11-21 13:56:31.763    1.07758   0.489131   1.025969    0.445634   \n",
      "20258  2024-11-21 13:56:31.764    1.07758   0.489131   1.025969    0.445634   \n",
      "20259  2024-11-21 13:56:31.764    1.07758   0.489131   1.025969    0.445634   \n",
      "\n",
      "       Theta_TP9  Theta_AF7  Theta_AF8  Theta_TP10  Alpha_TP9  ...    Gyro_X  \\\n",
      "0            NaN        NaN        NaN         NaN        NaN  ...       NaN   \n",
      "1       0.000000   1.027297   0.937403    0.000000   0.000000  ...  1.405640   \n",
      "2       0.000000   1.027297   0.937403    0.000000   0.000000  ...  1.405640   \n",
      "3       0.000000   1.027297   0.937403    0.000000   0.000000  ...  1.405640   \n",
      "4       0.000000   1.027297   0.937403    0.000000   0.000000  ...  1.405640   \n",
      "...          ...        ...        ...         ...        ...  ...       ...   \n",
      "20255   0.616907   0.129927   0.701287    0.247421   0.429564  ...  2.422485   \n",
      "20256   0.616907   0.129927   0.701287    0.247421   0.429564  ...  2.422485   \n",
      "20257   0.616907   0.129927   0.701287    0.247421   0.429564  ...  2.422485   \n",
      "20258   0.616907   0.129927   0.701287    0.247421   0.429564  ...  2.422485   \n",
      "20259   0.616907   0.129927   0.701287    0.247421   0.429564  ...  2.422485   \n",
      "\n",
      "        Gyro_Y    Gyro_Z  HeadBandOn  HSI_TP9  HSI_AF7  HSI_AF8  HSI_TP10  \\\n",
      "0          NaN       NaN         NaN      NaN      NaN      NaN       NaN   \n",
      "1     -1.42807  2.519684         1.0      4.0      1.0      1.0       4.0   \n",
      "2     -1.42807  2.519684         1.0      4.0      1.0      1.0       4.0   \n",
      "3     -1.42807  2.519684         1.0      4.0      1.0      1.0       4.0   \n",
      "4     -1.42807  2.519684         1.0      4.0      1.0      1.0       4.0   \n",
      "...        ...       ...         ...      ...      ...      ...       ...   \n",
      "20255 -1.61499  4.366455         1.0      2.0      1.0      1.0       4.0   \n",
      "20256 -1.61499  4.366455         1.0      2.0      1.0      1.0       4.0   \n",
      "20257 -1.61499  4.366455         1.0      2.0      1.0      1.0       4.0   \n",
      "20258 -1.61499  4.366455         1.0      2.0      1.0      1.0       4.0   \n",
      "20259 -1.61499  4.366455         1.0      2.0      1.0      1.0       4.0   \n",
      "\n",
      "       Battery                         Elements  \n",
      "0          NaN  /muse/event/connected Muse-9E89  \n",
      "1         95.0                              NaN  \n",
      "2         95.0                              NaN  \n",
      "3         95.0                              NaN  \n",
      "4         95.0                              NaN  \n",
      "...        ...                              ...  \n",
      "20255     95.0                              NaN  \n",
      "20256     95.0                              NaN  \n",
      "20257     95.0                              NaN  \n",
      "20258     95.0                              NaN  \n",
      "20259     95.0                              NaN  \n",
      "\n",
      "[20260 rows x 39 columns]\n",
      "CPU times: total: 188 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Get Current Working directory and append the data relative dir\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "Salt = cwd + r\"/data/salt\"\n",
    "Sour = cwd + r\"/data/sour\"\n",
    "\n",
    "#Hold file locations\n",
    "filesSour=[];\n",
    "filesSalt=[]; #add more later\n",
    "\n",
    "\n",
    "#populate file location arrays\n",
    "for file in os.listdir(Salt):\n",
    "    if file.endswith('csv'):\n",
    "        filesSalt.append(os.path.join(Salt,file))\n",
    "for file in os.listdir(Sour):\n",
    "    if file.endswith('csv'):\n",
    "        filesSour.append(os.path.join(Sour,file))\n",
    "#Test reading files by changing num\n",
    "\n",
    "num = 5;\n",
    "Salt_sample = pd.read_csv(filesSalt[num])\n",
    "Sour_sample =  pd.read_csv(filesSour[num])\n",
    "print(Salt_sample)\n",
    "print(Sour_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">6 files were added from the Salty category\n"
     ]
    }
   ],
   "source": [
    "#Mini-Summary of Block\n",
    "#print(f\">{len(filesSpicy)} files were added from the Spicy category\")\n",
    "print(f\">{len(filesSalt)} files were added from the Salty category\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features generated by the Muse 2 headband:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TimeStamp</td>\n",
       "      <td>Delta_TP9</td>\n",
       "      <td>Delta_AF7</td>\n",
       "      <td>Delta_AF8</td>\n",
       "      <td>Delta_TP10</td>\n",
       "      <td>Theta_TP9</td>\n",
       "      <td>Theta_AF7</td>\n",
       "      <td>Theta_AF8</td>\n",
       "      <td>Theta_TP10</td>\n",
       "      <td>Alpha_TP9</td>\n",
       "      <td>...</td>\n",
       "      <td>Gyro_X</td>\n",
       "      <td>Gyro_Y</td>\n",
       "      <td>Gyro_Z</td>\n",
       "      <td>HeadBandOn</td>\n",
       "      <td>HSI_TP9</td>\n",
       "      <td>HSI_AF7</td>\n",
       "      <td>HSI_AF8</td>\n",
       "      <td>HSI_TP10</td>\n",
       "      <td>Battery</td>\n",
       "      <td>Elements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3           4          5   \\\n",
       "0  TimeStamp  Delta_TP9  Delta_AF7  Delta_AF8  Delta_TP10  Theta_TP9   \n",
       "\n",
       "          6          7           8          9   ...      29      30      31  \\\n",
       "0  Theta_AF7  Theta_AF8  Theta_TP10  Alpha_TP9  ...  Gyro_X  Gyro_Y  Gyro_Z   \n",
       "\n",
       "           32       33       34       35        36       37        38  \n",
       "0  HeadBandOn  HSI_TP9  HSI_AF7  HSI_AF8  HSI_TP10  Battery  Elements  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Features generated by the Muse 2 headband:\")\n",
    "pd.DataFrame(Salt_sample.columns).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the RAW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:10\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\priyd\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\priyd\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\priyd\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\priyd\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    %%time\n",
    "    #Extract rows 21-25 from all files,\n",
    "    #these are the only 5 features relevant for use in the EEG_feature_extraction function\n",
    "    #rowsSpicy=[];\n",
    "    #for f in filesSpicy:\n",
    "    #   for r in range(pd.read_csv(f).shape[0]):\n",
    "    #       rowsSpicy.append(pd.read_csv(f).iloc[r,[0,21,22,23,24,25]])\n",
    "    rowsSalty=[];\n",
    "    for f in filesSalt:\n",
    "        for r in range(pd.read_csv(f).shape[0]):\n",
    "            rowsSalty.append(pd.read_csv(f).iloc[r,[0,21,22,23,24,25]])\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsSalty = []\n",
    "\n",
    "for f in filesSalt:\n",
    "    df = pd.read_csv(f)  # Read the file once\n",
    "    rowsSalty.extend(df.iloc[:, [0, 21, 22, 23, 24, 25]].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to DataFrames\n",
    "data_Spicy = pd.DataFrame(rowsSpicy);\n",
    "original_Spicy = data_Spicy.copy();\n",
    "data_Spicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-21 02:05:38.593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-21 02:05:38.626</td>\n",
       "      <td>796.996337</td>\n",
       "      <td>806.666667</td>\n",
       "      <td>829.230769</td>\n",
       "      <td>589.890110</td>\n",
       "      <td>766.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-21 02:05:38.626</td>\n",
       "      <td>817.948718</td>\n",
       "      <td>778.864469</td>\n",
       "      <td>826.007326</td>\n",
       "      <td>116.446886</td>\n",
       "      <td>728.498168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-21 02:05:38.626</td>\n",
       "      <td>809.487179</td>\n",
       "      <td>803.846154</td>\n",
       "      <td>839.304029</td>\n",
       "      <td>857.032967</td>\n",
       "      <td>741.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-21 02:05:38.627</td>\n",
       "      <td>802.637363</td>\n",
       "      <td>812.307692</td>\n",
       "      <td>840.915751</td>\n",
       "      <td>1467.069597</td>\n",
       "      <td>792.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191587</th>\n",
       "      <td>2024-11-21 14:05:25.887</td>\n",
       "      <td>772.417582</td>\n",
       "      <td>764.761905</td>\n",
       "      <td>884.029304</td>\n",
       "      <td>867.106227</td>\n",
       "      <td>803.040293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191588</th>\n",
       "      <td>2024-11-21 14:05:25.887</td>\n",
       "      <td>753.882784</td>\n",
       "      <td>772.014652</td>\n",
       "      <td>884.432234</td>\n",
       "      <td>850.183150</td>\n",
       "      <td>593.516484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191589</th>\n",
       "      <td>2024-11-21 14:05:25.887</td>\n",
       "      <td>741.391941</td>\n",
       "      <td>761.941392</td>\n",
       "      <td>869.120879</td>\n",
       "      <td>836.483516</td>\n",
       "      <td>606.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191590</th>\n",
       "      <td>2024-11-21 14:05:25.887</td>\n",
       "      <td>745.018315</td>\n",
       "      <td>757.106227</td>\n",
       "      <td>869.120879</td>\n",
       "      <td>857.032967</td>\n",
       "      <td>701.098901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191591</th>\n",
       "      <td>2024-11-21 14:05:25.887</td>\n",
       "      <td>747.838828</td>\n",
       "      <td>764.761905</td>\n",
       "      <td>881.611722</td>\n",
       "      <td>855.824176</td>\n",
       "      <td>600.366300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191592 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0           1           2           3  \\\n",
       "0       2024-11-21 02:05:38.593         NaN         NaN         NaN   \n",
       "1       2024-11-21 02:05:38.626  796.996337  806.666667  829.230769   \n",
       "2       2024-11-21 02:05:38.626  817.948718  778.864469  826.007326   \n",
       "3       2024-11-21 02:05:38.626  809.487179  803.846154  839.304029   \n",
       "4       2024-11-21 02:05:38.627  802.637363  812.307692  840.915751   \n",
       "...                         ...         ...         ...         ...   \n",
       "191587  2024-11-21 14:05:25.887  772.417582  764.761905  884.029304   \n",
       "191588  2024-11-21 14:05:25.887  753.882784  772.014652  884.432234   \n",
       "191589  2024-11-21 14:05:25.887  741.391941  761.941392  869.120879   \n",
       "191590  2024-11-21 14:05:25.887  745.018315  757.106227  869.120879   \n",
       "191591  2024-11-21 14:05:25.887  747.838828  764.761905  881.611722   \n",
       "\n",
       "                  4           5  \n",
       "0               NaN         NaN  \n",
       "1        589.890110  766.373626  \n",
       "2        116.446886  728.498168  \n",
       "3        857.032967  741.391941  \n",
       "4       1467.069597  792.564103  \n",
       "...             ...         ...  \n",
       "191587   867.106227  803.040293  \n",
       "191588   850.183150  593.516484  \n",
       "191589   836.483516  606.813187  \n",
       "191590   857.032967  701.098901  \n",
       "191591   855.824176  600.366300  \n",
       "\n",
       "[191592 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to DataFrames\n",
    "data_Salty = pd.DataFrame(rowsSalty);\n",
    "original_Salty = data_Salty.copy();\n",
    "data_Salty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salty data size is: \t(191592, 6)\n"
     ]
    }
   ],
   "source": [
    "#quick check of DataFrames\n",
    "#print(f\"Spicy data size is: \\t{data_Spicy.shape}\",f\"\\nSalty data size is: \\t{data_Salty.shape}\")\n",
    "print(f\"\\nSalty data size is: \\t{data_Salty.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Empty Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NaN values\n",
    "#data_Spicy = data_Spicy.dropna()\n",
    "data_Salty = data_Salty.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Datetime Column to Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required for compatibility with EEG_feature_extraction function\n",
    "from datetime import datetime\n",
    "\"\"\"\n",
    "    i = 0;\n",
    "    for time in data_Spicy.iloc[:,0]:\n",
    "        tmstmp = datetime.strptime(str(time),'%Y-%m-%d %H:%M:%S.%f').timestamp()\n",
    "        data_Spicy.iat[i,0] = (tmstmp);\n",
    "    i=i+1;\n",
    "\"\"\"\n",
    "i = 0;\n",
    "for time in data_Salty.iloc[:,0]:\n",
    "    tmstmp = datetime.strptime(str(time),'%Y-%m-%d %H:%M:%S.%f').timestamp()\n",
    "    data_Salty.iat[i,0] = (tmstmp);\n",
    "i=i+1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_Spicy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Quick Check\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata_Spicy\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_Spicy' is not defined"
     ]
    }
   ],
   "source": [
    "#Quick Check\n",
    "data_Spicy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1732226725.887</td>\n",
       "      <td>796.996337</td>\n",
       "      <td>806.666667</td>\n",
       "      <td>829.230769</td>\n",
       "      <td>589.890110</td>\n",
       "      <td>766.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-21 02:05:38.626</td>\n",
       "      <td>817.948718</td>\n",
       "      <td>778.864469</td>\n",
       "      <td>826.007326</td>\n",
       "      <td>116.446886</td>\n",
       "      <td>728.498168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-21 02:05:38.626</td>\n",
       "      <td>809.487179</td>\n",
       "      <td>803.846154</td>\n",
       "      <td>839.304029</td>\n",
       "      <td>857.032967</td>\n",
       "      <td>741.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-21 02:05:38.627</td>\n",
       "      <td>802.637363</td>\n",
       "      <td>812.307692</td>\n",
       "      <td>840.915751</td>\n",
       "      <td>1467.069597</td>\n",
       "      <td>792.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-21 02:05:38.627</td>\n",
       "      <td>794.981685</td>\n",
       "      <td>772.014652</td>\n",
       "      <td>820.769231</td>\n",
       "      <td>858.241758</td>\n",
       "      <td>838.095238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0           1           2           3            4  \\\n",
       "1           1732226725.887  796.996337  806.666667  829.230769   589.890110   \n",
       "2  2024-11-21 02:05:38.626  817.948718  778.864469  826.007326   116.446886   \n",
       "3  2024-11-21 02:05:38.626  809.487179  803.846154  839.304029   857.032967   \n",
       "4  2024-11-21 02:05:38.627  802.637363  812.307692  840.915751  1467.069597   \n",
       "5  2024-11-21 02:05:38.627  794.981685  772.014652  820.769231   858.241758   \n",
       "\n",
       "            5  \n",
       "1  766.373626  \n",
       "2  728.498168  \n",
       "3  741.391941  \n",
       "4  792.564103  \n",
       "5  838.095238  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Salty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data to File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative STARTING POINT once data collection is finalized. This step was done to bypass having to run the previous section each time which would take a very long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: C:\\Users\\priyd\\Downloads\\465_EEG_Group12\\data.csv\n"
     ]
    }
   ],
   "source": [
    "savelocSalty = r'C:\\Users\\priyd\\Downloads\\465_EEG_Group12\\data.csv'\n",
    "\n",
    "# Ensure the file exists before reading\n",
    "if os.path.exists(savelocSalty):\n",
    "    # Read the file into a DataFrame\n",
    "    df = pd.read_csv(savelocSalty, header=None)\n",
    "    df.columns = [f\"col{i}\" for i in range(1, len(df.columns) + 1)]\n",
    "    \n",
    "    # Save the DataFrame back to the file (if needed)\n",
    "    csv_data = df.to_csv(savelocSalty, mode='w', index=False)\n",
    "    \n",
    "    # Use StringIO to mimic file-like object for csv_data\n",
    "    file_like_object = StringIO(csv_data)\n",
    "    \n",
    "    # Display file preview and column count\n",
    "    print(\"Preview of the file:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nNumber of columns:\", len(df.columns))\n",
    "else:\n",
    "    print(f\"File not found: {savelocSalty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved at: data/data1_with_headers.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\priyd\\eeg-feature-generation\\eeg_feature_generation\")  # Use raw string to handle backslashes\n",
    "from eeg_feature_generation import EEG_feature_extraction as FG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#try various combinations of Nsamp and Perio\n",
    "Nsamp = 50;\n",
    "Perio = 6;\n",
    "\n",
    "xSpicy,ySpicy = FG.generate_feature_vectors_from_samples(file_path=savelocSpicy,\n",
    "                                                         nsamples=Nsamp,\n",
    "                                                         period=Perio,\n",
    "                                                         #state=data_Spicy.iloc[:,-1],\n",
    "                                                         slide_percent=0.05,\n",
    "                                                         remove_redundant=False,\n",
    "                                                         cols_to_ignore=None)\n",
    "xSpicy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'headers' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m Nsamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      3\u001b[0m Perio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 5\u001b[0m xSalty, ySalty \u001b[38;5;241m=\u001b[39m \u001b[43mFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_feature_vectors_from_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdated_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNsamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPerio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_redundant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcols_to_ignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of xSalty:\u001b[39m\u001b[38;5;124m\"\u001b[39m, xSalty\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\eeg-feature-generation\\eeg_feature_generation\\EEG_feature_extraction.py:887\u001b[0m, in \u001b[0;36mgenerate_feature_vectors_from_samples\u001b[1;34m(file_path, nsamples, period, state, remove_redundant, cols_to_ignore)\u001b[0m\n\u001b[0;32m    883\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m \t\t \u001b[38;5;66;03m# Remove the label (last column) of previous vector\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \t\tprevious_vector \u001b[38;5;241m=\u001b[39m previous_vector[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \n\u001b[1;32m--> 887\u001b[0m feat_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43mheaders\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m headers\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_redundant:\n\u001b[0;32m    890\u001b[0m \t\u001b[38;5;66;03m# Remove redundant lag window features\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \tto_rm \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_mean_q3_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_mean_q4_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_mean_d_q3q4_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    892\u001b[0m \t         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_max_q3_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_max_q4_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_max_d_q3q4_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    893\u001b[0m \t\t\t \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_min_q3_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_min_q4_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag1_min_d_q3q4_\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'headers' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#try various combinations of Nsamp and Perio\n",
    "Nsamp = 50\n",
    "Perio = 5\n",
    "\n",
    "xSalty, ySalty = FG.generate_feature_vectors_from_samples(\n",
    "    file_path=updated_file_path,\n",
    "    nsamples=Nsamp,\n",
    "    period=Perio,\n",
    "    remove_redundant=False,\n",
    "    cols_to_ignore=None\n",
    ")\n",
    "\n",
    "print(\"Shape of xSalty:\", xSalty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some quick checks\n",
    "X_Spicy = pd.DataFrame(np.real(xSpicy))\n",
    "X_Spicy.columns = np.hstack((['Timestamp'],ySpicy))\n",
    "X_Spicy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows',None,'display.max_columns',None):\n",
    "    display(pd.DataFrame(pd.DataFrame(X_Spicy).head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Salty = pd.DataFrame(np.real(xSalty))\n",
    "X_Salty.columns = np.hstack((['Timestamp'],ySalty))\n",
    "X_Salty.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Into Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_standardized = StandardScaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 225)\n",
    "X_pca = pca.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_standardized = StandardScaler.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(5,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(inputs, y_train, batch_size = 32, epochs = 100, validation_split=0.2, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
